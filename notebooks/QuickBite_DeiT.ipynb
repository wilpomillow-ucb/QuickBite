{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8ceefc-2d74-40fe-af18-0f59d8075860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install timm\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ac1c84a-a9d6-4d9f-a0db-7f1d532c4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "# import timm\n",
    "from timm import create_model\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157b5ad-1b8b-4137-97f1-bbc1ed1b6228",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Repurposed code from MobileNet model notebook. Changes made include directory reference to content folder, and the keep.csv is already filterd to the classes we wanted to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeaccabc-04c5-4168-a6c6-f469fb1a9e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['macaron', 'beignet', 'cruller', 'cockle_food', 'samosa', 'tiramisu', 'tostada', 'moussaka', 'dumpling', 'sashimi', 'knish', 'croquette', 'couscous', 'porridge', 'stuffed_cabbage', 'seaweed_salad', 'chow_mein', 'rigatoni', 'beef_tartare', 'cannoli', 'foie_gras', 'cupcake', 'osso_buco', 'pad_thai', 'poutine', 'ramen', 'pulled_pork_sandwich', 'bibimbap', 'chicken_kiev', 'apple_pie', 'risotto', 'fruitcake', 'chop_suey', 'haggis', 'scrambled_eggs', 'frittata', 'scampi', 'sushi', 'orzo', 'fritter', 'nacho', 'beef_stroganoff', 'beef_wellington', 'spring_roll', 'savarin', 'crayfish_food', 'souffle', 'adobo', 'streusel', 'deviled_egg', 'escargot', 'club_sandwich', 'carrot_cake', 'falafel', 'farfalle', 'terrine', 'poached_egg', 'gnocchi', 'bubble_and_squeak', 'egg_roll', 'caprese_salad', 'sauerkraut', 'creme_brulee', 'pavlova', 'fondue', 'scallop', 'jambalaya', 'tempura', 'chocolate_cake', 'potpie', 'spaghetti_bolognese', 'sukiyaki', 'applesauce', 'baklava', 'salisbury_steak', 'linguine', 'edamame', 'coq_au_vin', 'tamale', 'macaroni_and_cheese', 'kedgeree', 'garlic_bread', 'beet_salad', 'steak_tartare', 'vermicelli', 'pate', 'pancake', 'tetrazzini', 'onion_rings', 'red_velvet_cake', 'compote', 'lobster_food', 'chicken_curry', 'chicken_wing', 'caesar_salad', 'succotash', 'hummus', 'fish_and_chips', 'lasagna', 'lutefisk', 'sloppy_joe', 'gingerbread', 'crab_cake', 'sauerbraten', 'peking_duck', 'guacamole', 'ham_sandwich', 'crumpet', 'taco', 'strawberry_shortcake', 'clam_chowder', 'cottage_pie', 'croque_madame', 'french_onion_soup', 'beef_carpaccio', 'torte', 'poi', 'crab_food', 'bacon_and_eggs', 'coffee_cake', 'custard', 'syllabub', 'pork_chop', 'fried_rice', 'boiled_egg', 'galantine', 'brisket', 'reuben', 'schnitzel', 'ambrosia_food', 'gyoza', 'jerky', 'ravioli', 'fried_calamari', 'spaghetti_carbonara', 'miso_soup', 'frozen_yogurt', 'wonton', 'panna_cotta', 'french_toast', 'enchilada', 'ceviche', 'fettuccine', 'chili', 'flan', 'kabob', 'sponge_cake', 'casserole', 'paella', 'blancmange', 'bruschetta', 'tortellini', 'grilled_salmon', 'french_fries', 'shrimp_and_grits', 'churro', 'donut', 'meat_loaf_food', 'meatball', 'scrapple', 'strudel', 'coconut_cake', 'marble_cake', 'filet_mignon', 'hamburger', 'fried_egg', 'tuna_tartare', 'penne', 'eggs_benedict', 'bread_pudding', 'takoyaki', 'tenderloin', 'chocolate_mousse', 'baked_alaska', 'hot_dog', 'confit', 'ham_and_eggs', 'biryani', 'greek_salad', 'huevos_rancheros', 'tagliatelle', 'stuffed_peppers', 'cannelloni', 'pizza', 'sausage_roll', 'chicken_quesadilla', 'hot_and_sour_soup', 'prime_rib', 'cheesecake', 'limpet_food', 'ziti', 'mussel', 'manicotti', 'ice_cream', 'waffle', 'oyster', 'omelette', 'clam_food', 'burrito', 'roulade', 'lobster_bisque', 'grilled_cheese_sandwich', 'gyro', 'pound_cake', 'pho', 'lobster_roll_sandwich', 'baby_back_rib', 'tapenade', 'pepper_steak', 'welsh_rarebit', 'pilaf', 'dolmas', 'coquilles_saint_jacques', 'veal_cordon_bleu', 'shirred_egg', 'barbecued_wing', 'lobster_thermidor', 'steak_au_poivre', 'huitre', 'chiffon_cake', 'profiterole', 'toad_in_the_hole', 'chicken_marengo', 'victoria_sandwich', 'tamale_pie', 'boston_cream_pie', 'fish_stick', 'crumb_cake', 'chicken_provencale', 'vol_au_vent', 'entrecote', 'carbonnade_flamande', 'bacon_lettuce_tomato_sandwich', 'scotch_egg', 'pirogi', 'peach_melba', 'upside_down_cake', 'applesauce_cake', 'rugulah', 'rock_cake', 'barbecued_spareribs', 'beef_bourguignonne', 'rissole', 'mostaccioli', 'apple_turnover', 'matzo_ball', 'chicken_cordon_bleu', 'eccles_cake', 'moo_goo_gai_pan', 'buffalo_wing', 'stuffed_tomato'])\n"
     ]
    }
   ],
   "source": [
    "# Class list\n",
    "# uploaded class_list to colab session -- todo: revise for local usage\n",
    "class_list_path = r\"C:\\Users\\linay\\Downloads\\ifood-2019-fgvc6\\class_list.txt\"\n",
    "\n",
    "class_mapping = {}\n",
    "\n",
    "# Open the file and read the contents\n",
    "with open(class_list_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        # Split each line by space to separate the index and the class name\n",
    "        index, class_name = line.strip().split(' ', 1)\n",
    "        # Convert the index to an integer and add the mapping to the dictionary\n",
    "        class_mapping[int(index)] = class_name\n",
    "    print(class_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c20de36-e192-4795-80be-214ad2535b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes to train for : 25\n"
     ]
    }
   ],
   "source": [
    "# Reduce classes after EDA process\n",
    "keep_list = r\"C:\\Users\\linay\\Downloads\\ifood-2019-fgvc6\\keep.csv\"\n",
    "df_keep = pd.read_csv(keep_list)\n",
    "## commenting out the below code because I already filtered the csv file to all of the classes we wanted to keep\n",
    "# df_keep = df_keep[df_keep['All Agree']=='True']\n",
    "print(\"Classes to train for :\", len(df_keep))\n",
    "classes_to_keep = df_keep['category_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2d9819-470b-4f6e-a654-7e265dae8ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered class mapping: 25\n"
     ]
    }
   ],
   "source": [
    "# Convert to an array of label IDs for classes to keep\n",
    "filtered_class_mapping = {index: class_name for index, class_name in class_mapping.items() if class_name in classes_to_keep}\n",
    "print(\"Filtered class mapping:\", len(filtered_class_mapping))\n",
    "filtered_class_ids = list(map(str, filtered_class_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1773f88-2d0f-4005-bc76-0eb8e23bbe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of good data: 40631\n"
     ]
    }
   ],
   "source": [
    "# Check \"bad\" input test data, and return only those that are good\n",
    "type_1_data = pd.read_csv(r\"C:\\Users\\linay\\Downloads\\ifood-2019-fgvc6\\df_eda.csv\")\n",
    "type_1_data = type_1_data[(type_1_data['is_cartoon'] == False) & (type_1_data['has_face'] == False) & (type_1_data['is_media_art'] == False) & (type_1_data['has_text'] == False)]\n",
    "type_1_data = type_1_data['img_name'].to_list()\n",
    "print(\"count of good data:\", len(type_1_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6624d77-9589-4870-8c79-0059864bb04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of images that are in the filtered class in train set: 13578\n",
      "This is the number of images that are in the the filtered class and also are not bad images in train set: 5596\n",
      "This is the number of images that are in the validation set that are in the filtered class: 1263\n"
     ]
    }
   ],
   "source": [
    "# Paths to the dataset\n",
    "train_dir = r\"C:\\Users\\linay\\Downloads\\ifood-2019-fgvc6\\train_set\\train_set\"\n",
    "val_dir   = r\"C:\\Users\\linay\\Downloads\\ifood-2019-fgvc6\\val_set\\val_set\"\n",
    "test_dir  = r\"C:\\Users\\linay\\Downloads\\ifood-2019-fgvc6\\test_set\\test_set\"\n",
    "\n",
    "# Path to the labels\n",
    "df_train = pd.read_csv(r\"C:\\Users\\linay\\Downloads\\ifood-2019-fgvc6\\train_labels.csv\")\n",
    "df_val   = pd.read_csv(r\"C:\\Users\\linay\\Downloads\\ifood-2019-fgvc6\\val_labels.csv\")\n",
    "\n",
    "# TypeError: If class_mode=\"categorical\", y_col=\"label\" column values must be type string, list or tuple.\n",
    "df_train['label'] = df_train['label'].astype(str)\n",
    "df_val['label']   = df_val['label'].astype(str)\n",
    "\n",
    "# Filter datasets to just classifications of interest\n",
    "df_train = df_train[df_train['label'].isin(filtered_class_ids)]\n",
    "print(\"This is the number of images that are in the filtered class in train set:\", len(df_train))\n",
    "df_train = df_train[df_train['img_name'].isin(type_1_data)]\n",
    "print(\"This is the number of images that are in the the filtered class and also are not bad images in train set:\", len(df_train))\n",
    "df_val   = df_val[df_val['label'].isin(filtered_class_ids)]\n",
    "print(\"This is the number of images that are in the validation set that are in the filtered class:\", len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bbdc4f5-9b63-47a9-9cae-826d31419890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append a new column and store the image directory in the columns\n",
    "df_train['image_directory'] = ''\n",
    "for index, row in df_train.iterrows():\n",
    "    df_train.loc[index, 'image_directory'] = os.path.join(train_dir, row['img_name']) \n",
    "\n",
    "# change the labels to integer \n",
    "df_train['label'] = df_train['label'].astype(int)\n",
    "\n",
    "# append a new column and store the image directory in the colums \n",
    "df_val['image_directory'] = ''\n",
    "for index, row in df_val.iterrows():\n",
    "    df_val.loc[index, 'image_directory'] = os.path.join(val_dir, row['img_name']) \n",
    "\n",
    "df_val['label'] = df_val['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b2147cc-e427-404b-9f4c-47025e9e0b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of unique labels in the validation set: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the number of unique labels in the validation set:\", len(pd.unique(df_val['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7408a16-ad09-403d-a0da-463065870e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_val.to_csv('df_val_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fcda9c7-38ad-416a-afc1-a64e13b55dbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # CUTE DELETE LATER\n",
    "# # Remove the images that we want to keep for classification \n",
    "# # Create a new folder to store the filtered dataset \n",
    "# # Identify the images for just classification interest \n",
    "# image_names = df_train['img_name'].tolist()\n",
    "# print(\"number of images for training\", len(image_names)) \n",
    "# # instantiate an empty list to store matched images \n",
    "# matched_image_directory = []\n",
    "\n",
    "# # iterate through the file names and check if each image exists in the directory \n",
    "# count = 0\n",
    "# for image in image_names:\n",
    "#     curr_train_dir = os.path.join(train_dir, image)\n",
    "#     # testing current image train_dir (setting curr_train_dir for EACH image, using global train_dir variable)\n",
    "#     # if (count < 5):\n",
    "#     #     print(curr_train_dir)\n",
    "#     #     count += 1\n",
    "#     if os.path.exists(train_dir):\n",
    "#         matched_image_directory.append(train_dir)\n",
    "# # print or use the list of matched images\n",
    "# print(\"number of images in the directory:\", len(matched_image_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c0cc48-f289-4ed9-b423-b9a4568e0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CUTE DELETE LATER\n",
    "# create the destination directory to store all of the filtered,clean images\n",
    "# new_train_dir = r\"C:\\Users\\linay\\Downloads\\ifood-2019-fgvc6\\train_set\\train_set_filtered\"\n",
    "# if not os.path.exists(new_train_dir):\n",
    "#     os.makedirs(new_train_dir)\n",
    "    \n",
    "# if os.path.exists(new_train_dir):\n",
    "#     for filename in os.listdir(new_train_dir): \n",
    "#         file_path = os.path.join(new_train_dir, filename)\n",
    "#         if os.path.isfile(file_path):\n",
    "#             os.remove(file_path)\n",
    "#             # print(f\"Deleted file: {file_path}\")\n",
    "\n",
    "# for image in image_names:\n",
    "#     src_file_path = os.path.join(train_dir, image)\n",
    "#     # print(src_file_path)\n",
    "#     if os.path.exists(src_file_path):\n",
    "#         shutil.copy2(src_file_path, new_train_dir)\n",
    "#         # print(f\"Copied {file_name} to {new_train_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaef3dc-0b29-4322-91b7-e502092968f8",
   "metadata": {},
   "source": [
    "### Create and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9185ad06-26e5-4e22-9d45-123c49a85585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Transformed at: 2024-10-13 22:22:59.888046\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset and create data loader\n",
    "\n",
    "# takes the df_train pandas dataframe \n",
    "# and transforms as inputs and returns the image along with corresponding label\n",
    "class CustomImageDataset(Dataset): \n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.df.iloc[index, 2]  # assuming the image path is in the 3 column\n",
    "        label = self.df.iloc[index, 1]  # assuming the label is in the second column\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# # standard transformation\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(224),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# applying data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),  # Resize to 256x256\n",
    "    transforms.RandomCrop(224),  # Randomly crop to 224x224\n",
    "    transforms.RandomRotation(30),  # Randomly rotate up to 30 degrees\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip horizontally\n",
    "    transforms.RandomAffine(degrees=30, scale=(0.8, 1.2)),  # Randomly scale and rotate\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),  # Randomly jitter color\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# create training data set and data loader\n",
    "data_set = CustomImageDataset(df_train, transform)\n",
    "data_loader = DataLoader(data_set, batch_size=32, shuffle=True)\n",
    "\n",
    "# create validation dataset and data loader\n",
    "validation_data_set = CustomImageDataset(df_val, transform)\n",
    "validation_data_loader = DataLoader(validation_data_set, batch_size=32, shuffle=False)\n",
    "\n",
    "print('Data Transformed at:', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b3e147d-60bb-4a83-9dc2-3da72358948f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2024-10-13 22:28:41.807947\n",
      "Epoch 1: Loss = 2.0761, Validation Loss = 1.8783, Validation Accuracy Top1 = 0.4473, Validation Accuracy Top5 = 0.8052\n",
      "Epoch 2: Loss = 1.2718, Validation Loss = 1.3513, Validation Accuracy Top1 = 0.5914, Validation Accuracy Top5 = 0.9002\n",
      "Epoch 3: Loss = 0.9327, Validation Loss = 1.1474, Validation Accuracy Top1 = 0.6580, Validation Accuracy Top5 = 0.9161\n",
      "Epoch 4: Loss = 0.7109, Validation Loss = 1.2349, Validation Accuracy Top1 = 0.6334, Validation Accuracy Top5 = 0.9105\n",
      "Epoch 5: Loss = 0.8850, Validation Loss = 1.0774, Validation Accuracy Top1 = 0.6746, Validation Accuracy Top5 = 0.9272\n",
      "Epoch 6: Loss = 1.2863, Validation Loss = 1.1172, Validation Accuracy Top1 = 0.6611, Validation Accuracy Top5 = 0.9264\n",
      "Early stopping at epoch 7\n",
      "Epoch End Time: 2024-10-14 01:35:27.204442\n",
      "Validation Results End Time: 2024-10-14 01:37:19.846872\n"
     ]
    }
   ],
   "source": [
    "print('Start Time:', datetime.datetime.now())\n",
    "\n",
    "# Load pre-trained DeiT model\n",
    "model = create_model('deit_base_patch16_224', pretrained=True)\n",
    "# model.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "# Train the model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Instantiate lists to store training and validation loss and accuracy\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "train_accuracy_top1 = []\n",
    "train_accuracy_top5 = []\n",
    "val_loss = []\n",
    "val_accuracy = []\n",
    "val_accuracy_top1 = []\n",
    "val_accuracy_top5 = []\n",
    "lr_pg0 = []\n",
    "lr_pg1 = []\n",
    "lr_pg2 = []\n",
    "epochs = []\n",
    "\n",
    "# create a function to evaluate the model on the validation set \n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0 \n",
    "    total_correct_top1 = 0\n",
    "    total_correct_top5 = 0\n",
    "    confidence_values = [] \n",
    "    predicted_labels = []\n",
    "    image_paths = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted_top1 = torch.max(outputs, 1)\n",
    "            _, predicted_top5 = torch.topk(outputs, k=5, dim=1)\n",
    "            total_correct_top1 += (predicted_top1 == labels).sum().item()\n",
    "            total_correct_top5 += (labels.unsqueeze(1) == predicted_top5).any(dim=1).sum().item()\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidence_values.extend(probs[range(len(labels)), labels].cpu().numpy())\n",
    "            predicted_labels.extend(predicted_top1.cpu().numpy())  # <--- Use predicted_top1 instead of labels\n",
    "            image_paths.extend([data_loader.dataset.df.iloc[i, 2] for i in range(len(labels))])         \n",
    "    accuracy_top1 = total_correct_top1 / len(data_loader.dataset)\n",
    "    accuracy_top5 = total_correct_top5 / len(data_loader.dataset)\n",
    "    return total_loss / len(data_loader), accuracy_top1, accuracy_top5, confidence_values, predicted_labels, image_paths\n",
    "\n",
    "# instantiate the patience count and minimum delta\n",
    "patience = 7\n",
    "min_delta = 0.0005\n",
    "\n",
    "best_val_accuracy = 0\n",
    "patience_count = 0\n",
    "\n",
    "for epoch in range(50):\n",
    "    total_loss = 0 \n",
    "    total_correct_top1 = 0\n",
    "    total_correct_top5 = 0\n",
    "    for images, labels in data_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels.squeeze())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted_top1 = torch.max(outputs, 1)\n",
    "        _, predicted_top5 = torch.topk(outputs, k=5, dim=1)\n",
    "        total_correct_top1 += (predicted_top1 == labels).sum().item()\n",
    "        total_correct_top5 += (labels.unsqueeze(1) == predicted_top5).any(dim=1).sum().item()\n",
    "    \n",
    "    # Calculate training loss and accuracy\n",
    "    train_loss.append(total_loss / len(data_loader))\n",
    "    train_accuracy_top1.append(total_correct_top1 / len(data_loader.dataset))\n",
    "    train_accuracy_top5.append(total_correct_top5 / len(data_loader.dataset))\n",
    "    lr_pg0.append(optimizer.param_groups[0]['lr'])\n",
    "    lr_pg1.append(optimizer.param_groups[0]['lr'])\n",
    "    lr_pg2.append(optimizer.param_groups[0]['lr'])\n",
    "    epochs.append(epoch+1)\n",
    "\n",
    "    # evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    validation_loss, validation_accuracy_top1, validation_accuracy_top5, confidence_values, labels, image_paths = evaluate(model, validation_data_loader)\n",
    "    val_loss.append(validation_loss)\n",
    "    val_accuracy_top1.append(validation_accuracy_top1)\n",
    "    val_accuracy_top5.append(validation_accuracy_top5)\n",
    "    \n",
    "    # check to see if validation loss has improved \n",
    "    # stop if plateaus \n",
    "    if validation_accuracy_top5 < best_val_accuracy - min_delta:\n",
    "        best_val_accuracy = validation_accuracy_top5\n",
    "        patience_count = 0\n",
    "    else:\n",
    "        patience_count += 1\n",
    "\n",
    "    if patience_count >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break    \n",
    "\n",
    "    # print loss and accuracy for each epoch \n",
    "    print('Epoch {}: Loss = {:.4f}, Validation Loss = {:.4f}, Validation Accuracy Top1 = {:.4f}, Validation Accuracy Top5 = {:.4f}'.format(epoch+1, loss.item(), validation_loss, validation_accuracy_top1, validation_accuracy_top5))\n",
    "\n",
    "print('Epoch End Time:', datetime.datetime.now())\n",
    "\n",
    "# # create a dataframe to store images, predicted labels, and confidence values\n",
    "confidence_values = []\n",
    "image_paths = []\n",
    "predicted_labels = []\n",
    "batch_indices = []\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(validation_data_loader):\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        confidence_values.extend(probs[range(len(labels)), labels].cpu().numpy())\n",
    "        batch_indices.extend(validation_data_loader.dataset.df.index[i*validation_data_loader.batch_size:(i+1)*validation_data_loader.batch_size])\n",
    "        image_paths.extend(validation_data_loader.dataset.df.loc[batch_indices[-len(labels):], 'image_directory'])\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "confidence_values_df = pd.DataFrame({'image_directory': image_paths, 'label': predicted_labels, 'confidence': confidence_values})\n",
    "confidence_values_df.to_csv('confidence_values.csv', index=False)\n",
    "\n",
    "print('Validation Results End Time:', datetime.datetime.now())\n",
    "\n",
    "## Store Training Log as a CSV\n",
    "# Create a dictionary to store the training log csv\n",
    "data = {\n",
    "    'Epoch': epochs,\n",
    "    'Train/Loss': train_loss,\n",
    "    'Train_Metrics/Accuracy_Top1': train_accuracy_top1,\n",
    "    'Train_Metrics/Accuracy_Top5': train_accuracy_top5,\n",
    "    'Val/Loss': val_loss,\n",
    "    'Val_Metrics/Accuracy_Top1': val_accuracy_top1,\n",
    "    'Val_Metrics/Accuracy_Top5': val_accuracy_top5,\n",
    "    'LR/Pg0': lr_pg0,\n",
    "    'LR/Pg1': lr_pg1,\n",
    "    'LR/Pg2': lr_pg2,\n",
    "} \n",
    "\n",
    "# Convert the dictionary to a Pandas DataFrame\n",
    "training_log_df = pd.DataFrame(data)\n",
    "\n",
    "# Store the DataFrame to a CSV file\n",
    "training_log_df.to_csv('deit_training_log.csv', index=False)\n",
    "\n",
    "## Store Validation Results as a CSV\n",
    "# Read in class list text file into df\n",
    "class_df = pd.read_csv('class_list.txt', sep=' ', names=['label', 'class'], index_col=None)\n",
    "\n",
    "# append true labels from validation df \n",
    "validation_results_df = pd.merge(confidence_values_df, df_val, on='image_directory')\n",
    "\n",
    "# rename labels to true and predicted\n",
    "validation_results_df = validation_results_df.rename(columns={\n",
    "    'label_x': 'predicted_labels',\n",
    "    'label_y': 'true_labels'\n",
    "})\n",
    "\n",
    "# append class for true labels\n",
    "validation_results_df['true_class'] = validation_results_df['true_labels'].map(class_df.set_index('label')['class'])\n",
    "\n",
    "# append class for predicted labels \n",
    "validation_results_df['predicted_class'] = validation_results_df['predicted_labels'].map(class_df.set_index('label')['class'])\n",
    "\n",
    "# reorder columns \n",
    "validation_results_df = validation_results_df.reindex(columns=['image_directory', 'img_name', 'true_labels', 'true_class', 'predicted_labels', 'predicted_class', 'confidence'])\n",
    "\n",
    "validation_results_df.to_csv('validation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ef7e148-f793-4a29-a8fa-dcf78736630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted AUC-ROC score: 0.500264838031961\n",
      "0.6690419635787807 0.6997493566728048 0.6620434517703027 0.6605874531959894\n",
      "Top 3 accuracy: 0.6690419635787807\n"
     ]
    }
   ],
   "source": [
    "# Summary Metrics\n",
    "accuracy = accuracy_score(validation_results_df['true_labels'], validation_results_df['predicted_labels'])\n",
    "precision = precision_score(validation_results_df['true_labels'], validation_results_df['predicted_labels'], average='macro')\n",
    "recall = recall_score(validation_results_df['true_labels'], validation_results_df['predicted_labels'], average='macro', zero_division=0)\n",
    "f1 = f1_score(validation_results_df['true_labels'], validation_results_df['predicted_labels'], average='macro', zero_division=0)\n",
    "\n",
    "# auc roc score\n",
    "lb = LabelBinarizer()\n",
    "y_true = lb.fit_transform(validation_results_df['true_labels'])\n",
    "y_pred_proba = np.array([validation_results_df['confidence']]*y_true.shape[1]).T\n",
    "\n",
    "# Calculate the weighted AUC-ROC score\n",
    "auc_roc_weighted = roc_auc_score(y_true, y_pred_proba, average='weighted')\n",
    "\n",
    "# # Calculate the roc_auc_score for each class\n",
    "# for i in range(y_true.shape[1]):\n",
    "#     auc_roc = roc_auc_score(y_true[:, i], validation_results_df['confidence'])\n",
    "#     print(f\"AUC-ROC for class {i}: {auc_roc}\")\n",
    "\n",
    "# Get the top 3 predicted labels\n",
    "top_3_predicted_labels = []\n",
    "for i in range(len(validation_results_df['confidence'])):\n",
    "    top_3_indices = np.argsort(validation_results_df['confidence'].iloc[i])[-3:][::-1]\n",
    "    top_3_predicted_labels.append(np.array([validation_results_df['predicted_labels'].iloc[i]]))\n",
    "\n",
    "# Check if true label is in top 3 predicted labels\n",
    "correct_top_3 = [x in y for x, y in zip(validation_results_df['true_labels'], top_3_predicted_labels)]\n",
    "\n",
    "# Calculate the top 3 accuracy\n",
    "top_3_accuracy = np.mean(correct_top_3)\n",
    "\n",
    "# print(f'Top 3 Accuracy: {top_3_accuracy}')\n",
    "print(f\"Weighted AUC-ROC score: {auc_roc_weighted}\")\n",
    "print(accuracy, precision, recall, f1)\n",
    "print(f\"Top 3 accuracy: {top_3_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
